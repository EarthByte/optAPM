{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generates trench migation data required for optimisation routine.\n",
    "\n",
    "When extracting topologies - choose \"Resolved Toplogies (CitcomS specific) and UNCHECK the dateline option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import convergence\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pygplates as pgp\n",
    "import subduction_convergence_for_absolute_plate_motion as scap\n",
    "import obj_func_convergence\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muller 2016\n",
    "# starting_rotfile = '/Users/Mike/PhD/Plate_Models/Muller_etal_2016/Global_EarthByte_230-0Ma_GK07_AREPS.rot'\n",
    "# output_data_dir = '/Users/Mike/PhD/Plate_Models/Muller_etal_2016/Resolved_subduction_zones/'\n",
    "# topologies = '/Users/Mike/PhD/Plate_Models/Muller_etal_2016/Global_EarthByte_230-0Ma_GK07_AREPS_PlateBoundaries.gpml'\n",
    "\n",
    "# Shephard 2016\n",
    "# starting_rotfile = '/Users/Mike/PhD/Plate_Models/Shephard_etal_2013_ESR/GPlates/Shephard_etal_ESR2013_Global_EarthByte_2013.rot'\n",
    "# output_data_dir = '/Users/Mike/PhD/Plate_Models/Shephard_etal_2013_ESR/GPlates/Resolved_subduction_zones/'\n",
    "# topologies = '/Users/Mike/PhD/Plate_Models/Shephard_etal_2013_ESR/GPlates/Shephard_etal_ESR2013_Global_EarthByte_2013.gpml'\n",
    "\n",
    "# Optimised model\n",
    "model = '149'\n",
    "timeStart = 81\n",
    "\n",
    "# Muller 2016\n",
    "starting_rotfile = '/Users/Mike/Projects/optAPM/model_output_0-80Ma/optAPM' + model + \\\n",
    "                    '/Global_EarthByte_230-0Ma_GK07_AREPS_optAPM' + model + '.rot'\n",
    "\n",
    "# Shephard 2013    \n",
    "# starting_rotfile = '/Users/Mike/Projects/optAPM/model_output_0-80Ma/optAPM' + model + \\\n",
    "#                    '/Shephard_etal_ESR2013_Global_EarthByte_2013_optAPM' + model + '.rot'\n",
    "\n",
    "# Muller 2016 alternative reference frames\n",
    "# starting_rotfile = '/Users/Mike/PhD/Plate_Models/Muller_etal_2016/Alternative_reference_frames/' + \\\n",
    "#                    'Global_EarthByte_230-0Ma_GK07_AREPS_' + model + '.rot'\n",
    "\n",
    "output_data_dir = '/Users/Mike/Projects/optAPM/model_output_0-80Ma/optAPM' + model + \\\n",
    "                  '/Subduction_zone_params/Resolved_topologies/'\n",
    "    \n",
    "# output_data_dir = '/Users/Mike/PhD/Plate_Models/Muller_etal_2016/Alternative_reference_frames/Resolved_topologies/' + model + '/'\n",
    "\n",
    "topologies = '/Users/Mike/PhD/Plate_Models/Muller_etal_2016/Global_EarthByte_230-0Ma_GK07_AREPS_PlateBoundaries.gpml'\n",
    "#topologies = '/Users/Mike/PhD/Plate_Models/Shephard_etal_2013_ESR/GPlates/Shephard_etal_ESR2013_Global_EarthByte_2013.gpml'\n",
    "\n",
    "starting_rotation_model = pgp.RotationModel(starting_rotfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW VERSION (can resolve topological lines)\n",
    "\n",
    "# %%timeit\n",
    "\n",
    "import subduction_convergence_for_absolute_plate_motion as scap\n",
    "\n",
    "for i in xrange(0, timeStart):\n",
    "    \n",
    "    time = i\n",
    "\n",
    "    # Resolve subduction zone features\n",
    "    resolved_subduction_zone_features = scap.resolve_subduction_zones(starting_rotation_model, topologies, time)\n",
    "\n",
    "    # Write to gpml file\n",
    "    pgp.FeatureCollection(resolved_subduction_zone_features).write(output_data_dir + 'TMData_' + str(time) + 'Ma.gpml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Old method\n",
    "# model = 'optAPM105'\n",
    "\n",
    "# input_rotation_filename = \\\n",
    "# '/Users/Mike/Projects/optAPM/model_output_0-80Ma/' + model + '/Global_EarthByte_230-0Ma_GK07_AREPS_' + model + '.rot'\n",
    "\n",
    "# MinTime = 0\n",
    "# MaxTime = 80\n",
    "# TimeStep = 1\n",
    "\n",
    "# DATAPATH = '/Users/Mike/Projects/optAPM/model_output_0-80Ma/' + model + '/Subduction_zone_params/Resolved_topologies'\n",
    "# outputFileStem = '/Users/Mike/Projects/optAPM/model_output_0-80Ma/' + model + '/Subduction_zone_params/CSV'\n",
    "\n",
    "# #DATAPATH = '/Users/Mike/PhD/Plate_Models/Muller_etal_2016/Alternative_reference_frames/Resolved_topologies/Muller1993'\n",
    "# #outputFileStem = '/Users/Mike/PhD/Plate_Models/Muller_etal_2016/Alternative_reference_frames/Resolved_topologies/Muller1993/CSV'\n",
    "\n",
    "# TimeStepList = np.arange(MinTime,MaxTime+1,TimeStep)\n",
    "\n",
    "# for TIME in TimeStepList:\n",
    "    \n",
    "#     # Perform check if file is within subfolder\n",
    "#     if os.path.exists(DATAPATH + '/topology_subduction_boundaries_sL_' + str(TIME) + '.00Ma'):\n",
    "\n",
    "#         shapeLeft = DATAPATH + '/topology_subduction_boundaries_sL_' + str(TIME) + \\\n",
    "#                                 '.00Ma/topology_subduction_boundaries_sL_' + str(TIME) + '.00Ma_polyline.shp'\n",
    "\n",
    "#     else: \n",
    "\n",
    "#         shapeLeft = DATAPATH + '/topology_subduction_boundaries_sL_' + str(TIME) + '.00Ma.shp'\n",
    "\n",
    "\n",
    "#     # Perform check if file is within subfolder   \n",
    "#     if os.path.exists(DATAPATH + '/topology_subduction_boundaries_sR_' + str(TIME) + '.00Ma'):\n",
    "\n",
    "#         shapeRight = DATAPATH + '/topology_subduction_boundaries_sR_' + str(TIME) + \\\n",
    "#                                 '.00Ma/topology_subduction_boundaries_sR_' + str(TIME) + '.00Ma_polyline.shp'\n",
    "\n",
    "#     else: \n",
    "\n",
    "#         shapeRight = DATAPATH + '/topology_subduction_boundaries_sR_' + str(TIME) + '.00Ma.shp'\n",
    "\n",
    "#     shapeTopo = DATAPATH + '/topology_platepolygons_'+ str(TIME) + '.00Ma.shp'\n",
    "\n",
    "#     timeFrom = TIME+TimeStep\n",
    "#     timeTo = TIME\n",
    "    \n",
    "    \n",
    "#     #------------------------\n",
    "#     # Use to create CSV files for trench migration histogram\n",
    "    \n",
    "#     outputFile = outputFileStem + '/subStats_'+str(TIME)+'.csv'\n",
    "    \n",
    "#     try:\n",
    "#         cA = convergence.main(shapeTopo,shapeLeft,shapeRight,input_rotation_filename,timeFrom,timeTo,outputFile)\n",
    "#         cA = np.array(cA)\n",
    "#         np.savetxt(outputFile, cA, delimiter=',',fmt='%1.5f')\n",
    "        \n",
    "#     except Exception as e:\n",
    "        \n",
    "#         print 'failed for time '+str(TIME)\n",
    "#         print e\n",
    "#         print \"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate trench migration input files\n",
    "\n",
    "Only need to do this once for new rotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OLD VERSION (can't resolve some newer style topologies)\n",
    "#------------------------\n",
    "# Use to create TMDATA for optimisation\n",
    "    \n",
    "# Read the plate topologies\n",
    "# [recsSubL,shapesSubL,fieldsSubL,NshpSubL]=convergence.readTopologyPlatepolygonFile(shapeLeft,'L')\n",
    "# [recsSubR,shapesSubR,fieldsSubR,NshpSubR]=convergence.readTopologyPlatepolygonFile(shapeRight,'R')\n",
    "# [recsTopo,shapesTopo,fieldsTopo,NshpTopo]=convergence.readTopologyPlatepolygonFile(shapeTopo,'T')\n",
    "\n",
    "# #Loop through the LH and RH subduction zones\n",
    "# subArrayL=convergence.subLoop(recsSubL,shapesSubL,fieldsSubL,NshpSubL,recsTopo,shapesTopo,fieldsTopo,NshpTopo,False)\n",
    "# subArrayR=convergence.subLoop(recsSubR,shapesSubR,fieldsSubR,NshpSubR,recsTopo,shapesTopo,fieldsTopo,NshpTopo,True)\n",
    "# subArray=subArrayL+subArrayR\n",
    "\n",
    "# #Interpolate the boundary data\n",
    "# reformArray = convergence.reformatData(subArray)\n",
    "\n",
    "# FNAME = outputFileStem + 'data_%s_%s.txt' % (timeFrom,timeTo)\n",
    "# with open(FNAME, 'w') as outfile:\n",
    "\n",
    "#     json.dump(reformArray, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcStats(trench_vel, mean):\n",
    "\n",
    "#     trench_vel = []\n",
    "\n",
    "#     for i in xrange(0, len(tm_stats)):\n",
    "\n",
    "#         trench_vel.append(tm_stats[i][2])\n",
    "\n",
    "    trench_vel = np.array(trench_vel)\n",
    "    trench_vel = trench_vel * 10\n",
    "\n",
    "    trench_vel_SD = np.std(trench_vel)\n",
    "    trench_numRetreating = len(np.where(trench_vel > 0)[0])\n",
    "    trench_numAdvancing = len(trench_vel) - trench_numRetreating\n",
    "    trench_numOver30 = len(np.where(trench_vel > 30)[0])\n",
    "    trench_numLessNeg30 = len(np.where(trench_vel < -30)[0])\n",
    "    trench_numTotal = len(trench_vel)\n",
    "    trench_sumAbsVel_n = np.sum(np.abs(trench_vel)) / len(trench_vel)\n",
    "\n",
    "    trench_percent_retreat = round((np.float(trench_numRetreating) / np.float(trench_numTotal)) * 100, 2)\n",
    "    trench_percent_advance = 100. - trench_percent_retreat\n",
    "\n",
    "    if mean == 1:\n",
    "        print 'Total: ', trench_numTotal / 10\n",
    "        \n",
    "    elif mean == 0:\n",
    "        print 'Total: ', trench_numTotal\n",
    "        \n",
    "    print 'SD: ', trench_vel_SD\n",
    "    print 'Num retreating: ', trench_numRetreating\n",
    "    print 'Num advancing: ', trench_numAdvancing\n",
    "    print 'Num > 30: ', trench_numOver30\n",
    "    print 'Num < -30: ', trench_numLessNeg30\n",
    "    print 'Abs vel mean: ', trench_sumAbsVel_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "\n",
    "ref_rotation_start_age = 80\n",
    "ref_rotation_end_age = 0\n",
    "\n",
    "tm_vel_all = []\n",
    "tm_obl_all = []\n",
    "\n",
    "for i in xrange(ref_rotation_end_age + 1, ref_rotation_start_age + 1):\n",
    "\n",
    "    tm_data = pgp.FeatureCollection('/Users/Mike/PhD/Plate_Models/Muller_etal_2016/Resolved_subduction_zones/TMData_%sMa.gpml' % i)\n",
    "\n",
    "    tm_stats = scap.subduction_absolute_motion(starting_rotation_model,\n",
    "                                               tm_data,\n",
    "                                               np.radians(1.),\n",
    "                                               i)\n",
    "    \n",
    "    for j in xrange(0, len(tm_stats)):\n",
    "    \n",
    "        tm_vel_all.append(tm_stats[j][2])\n",
    "        tm_obl_all.append(tm_stats[j][3])\n",
    "        \n",
    "print \"Mean TM Data @ \" + str(ref_rotation_start_age) + \"-\" + str(ref_rotation_end_age) + \"Ma\"\n",
    "print \"\"\n",
    "\n",
    "tm_vel_all_calc = np.abs(tm_vel_all) * -np.cos(np.radians(tm_obl_all)) \n",
    "        \n",
    "calcStats(tm_vel_all_calc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_data = pgp.FeatureCollection('/Users/Mike/PhD/Plate_Models/Muller_etal_2016/Resolved_subduction_zones/TMData_%sMa.gpml' % ref_rotation_start_age)\n",
    "\n",
    "tm_stats = scap.subduction_absolute_motion(starting_rotation_model,\n",
    "                                           tm_data,\n",
    "                                           np.radians(1.),\n",
    "                                           ref_rotation_start_age)\n",
    "\n",
    "tm_vel = []\n",
    "tm_obl = []\n",
    "\n",
    "for i in xrange(0, len(tm_stats)):\n",
    "    \n",
    "    tm_vel.append(tm_stats[i][2])\n",
    "    tm_obl.append(tm_stats[i][3])\n",
    "    \n",
    "print \"TM Data @ \" + str(ref_rotation_start_age) + \"Ma\"\n",
    "print \"\"\n",
    "\n",
    "tm_vel = np.array(tm_vel)\n",
    "tm_obl = np.array(tm_obl)\n",
    "\n",
    "tm_vel_calc = np.abs(tm_vel) * -np.cos(np.radians(tm_obl)) \n",
    "    \n",
    "calcStats(tm_vel, 0)\n",
    "\n",
    "plt.plot(range(0, len(tm_vel)), tm_vel)\n",
    "plt.show()\n",
    "\n",
    "calcStats(tm_vel_calc, 0)\n",
    "\n",
    "plt.plot(range(0, len(tm_vel_calc)), tm_vel_calc)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(tm_vel_calc, bins=25, normed=1)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(tm_vel, bins=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnr_datadir = '/Users/Mike/PhD/Plate_Models/Muller_etal_2016/TMdata/'\n",
    "\n",
    "FNAME = nnr_datadir + 'data_%s_%s.txt' % (int(ref_rotation_start_age), int(ref_rotation_end_age))\n",
    "with open(FNAME, 'r') as f:\n",
    "    reformArray = json.load(f)\n",
    "\n",
    "kinArray = obj_func_convergence.kinloop(ref_rotation_end_age, ref_rotation_start_age, reformArray, \n",
    "                                                    starting_rotation_model)\n",
    "\n",
    "cA = obj_func_convergence.kinstats(kinArray)\n",
    "cA = np.array(cA)\n",
    "\n",
    "trench_vel = -cA[:,6]\n",
    "trench_vel_SD = np.std(trench_vel)\n",
    "trench_numRetreating = len(np.where(trench_vel > 0)[0])\n",
    "trench_numAdvancing = len(trench_vel) - trench_numRetreating\n",
    "trench_numOver30 = len(np.where(trench_vel > 30)[0])\n",
    "trench_numLessNeg30 = len(np.where(trench_vel < -30)[0])\n",
    "trench_numTotal = len(trench_vel)\n",
    "trench_sumAbsVel_n = np.sum(np.abs(trench_vel)) / len(trench_vel)\n",
    "\n",
    "trench_percent_retreat = round((np.float(trench_numRetreating) / np.float(trench_numTotal)) * 100, 2)\n",
    "trench_percent_advance = 100. - trench_percent_retreat\n",
    "\n",
    "print \"Convergence TM data using 'data_20_10.txt'\"\n",
    "print \"\"\n",
    "\n",
    "print 'Total: ', trench_numTotal\n",
    "print 'SD: ', trench_vel_SD\n",
    "print 'Num retreating: ', trench_numRetreating\n",
    "print 'Num advancing: ', trench_numAdvancing\n",
    "print 'Num > 30: ', trench_numOver30\n",
    "print 'Num < -30: ', trench_numLessNeg30\n",
    "print 'Abs vel mean: ', trench_sumAbsVel_n\n",
    "\n",
    "plt.plot(range(0, len(trench_vel)), trench_vel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
