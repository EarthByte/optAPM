#!/bin/bash

# Name.
#PBS -N mpi4py-python-2.7.15-openmpi-gcc

# Project.
#PBS -P BGH

# CPUs.
#
# Ideally the number of seed models (eg, 100) divided by this number
# should be an integer (eg, 100 / 50 = 2).
# This is because each MPI process gets allocated a fixed number of seed models.
# If it's not an integer then some processes get allocated more than others
# (which causes the processes allocated fewer seed models to idle while waiting).
#PBS -l select=40:ncpus=5:mpiprocs=5:mem=1Gb

# Time limit.
#PBS -l walltime=4:00:00

# Queue.
#
# Dietmar has a strategic allocation.
# So allocating over 24 cores no longer results in a long queue delay (compared to not specifying the queue).
#PBS -q alloc-dm

# Set up the environment.
module load glew
module load proj
module load gdal
module load qt/4.8.6
module load qwt/6.1.3
module load cgal
module load boost
module load python/2.7.15
module load gmp/5.1.3
module load openmpi-gcc

cd $PBS_O_WORKDIR
export PYTHONPATH=$PYTHONPATH:/home/jscannon/gplates/builds/latest/python-api-2013-jul-25-build/bin

# Run the job.
mpirun -np 200 python Optimised_APM.py
